{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Projet 5 :** Segmentez des clients d'un site e-commerce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook de nettoyage et d'ingestion des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# configurations pandas\n",
    "pd.set_option('display.max_rows', 250)\n",
    "pd.set_option('display.max_columns', 250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement et nettoyage des données **geolocation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000163 entries, 0 to 1000162\n",
      "Data columns (total 5 columns):\n",
      " #   Column                       Non-Null Count    Dtype  \n",
      "---  ------                       --------------    -----  \n",
      " 0   geolocation_zip_code_prefix  1000163 non-null  int64  \n",
      " 1   geolocation_lat              1000163 non-null  float64\n",
      " 2   geolocation_lng              1000163 non-null  float64\n",
      " 3   geolocation_city             1000163 non-null  object \n",
      " 4   geolocation_state            1000163 non-null  object \n",
      "dtypes: float64(2), int64(1), object(2)\n",
      "memory usage: 38.2+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 19015 entries, 0 to 999846\n",
      "Data columns (total 3 columns):\n",
      " #   Column                       Non-Null Count  Dtype \n",
      "---  ------                       --------------  ----- \n",
      " 0   geolocation_zip_code_prefix  19015 non-null  int64 \n",
      " 1   geolocation_city             19015 non-null  object\n",
      " 2   geolocation_state            19015 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 594.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# GEOLOCATION\n",
    "\n",
    "df_geo = pd.read_csv(\"./data/olist_geolocation_dataset.csv\", sep=',', header=0)\n",
    "df_geo.info()\n",
    "df_geo.drop_duplicates(inplace=True)\n",
    "\n",
    "# On normalize autant que possible le texte\n",
    "df_geo['geolocation_city'] = df_geo['geolocation_city'].apply(lambda x : unidecode(str(x).lower()))\n",
    "df_geo['geolocation_state'] = df_geo['geolocation_state'].apply(lambda x : unidecode(str(x).lower()))\n",
    "\n",
    "# On ne garde que un unique zipcode car les customers ne sont catégorisés que par leurs zipcode\n",
    "df_geo_lite = df_geo.drop(columns=['geolocation_lat', 'geolocation_lng'], axis=1)\n",
    "df_geo_lite.drop_duplicates(subset=['geolocation_zip_code_prefix'], keep='first', inplace=True)\n",
    "\n",
    "print(df_geo_lite.info())\n",
    "\n",
    "# Save lite df\n",
    "file = './data/olist_geolocation_dataset_lite.csv'\n",
    "with open(file, 'wb+') as f:\n",
    "    _ = df_geo_lite.to_csv(f, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement et nettoyage des données **customers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99441 entries, 0 to 99440\n",
      "Data columns (total 5 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   customer_id               99441 non-null  object\n",
      " 1   customer_unique_id        99441 non-null  object\n",
      " 2   customer_zip_code_prefix  99441 non-null  int64 \n",
      " 3   customer_city             99441 non-null  object\n",
      " 4   customer_state            99441 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 3.8+ MB\n",
      "254 'customer_unique_id' dupliqué !\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 96350 entries, 0 to 99440\n",
      "Data columns (total 2 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   customer_unique_id        96350 non-null  object\n",
      " 1   customer_zip_code_prefix  96350 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.2+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# CUSTOMERS\n",
    "\n",
    "df_customers = pd.read_csv(\"./data/olist_customers_dataset.csv\", sep=',', header=0)\n",
    "df_customers.info()\n",
    "df_customers.drop_duplicates(inplace=True)\n",
    "\n",
    "# On normalize autant que possible le texte\n",
    "df_customers['customer_city'] = df_customers['customer_city'].apply(lambda x : unidecode(str(x).lower()))\n",
    "df_customers['customer_state'] = df_customers['customer_state'].apply(lambda x : unidecode(str(x).lower()))\n",
    "\n",
    "# On drop \"city\" et \"state\" car redondent\n",
    "df_customers_lite = df_customers.drop(columns=['customer_city', 'customer_state', 'customer_id'], axis=1).drop_duplicates()\n",
    "\n",
    "nb_duplicated = df_customers_lite[df_customers_lite.duplicated(subset=['customer_unique_id'], keep='first') == True].shape[0]\n",
    "print(f\"{nb_duplicated} 'customer_unique_id' dupliqué !\\n\")\n",
    "print(df_customers_lite.info())\n",
    "\n",
    "df_customers_lite.drop_duplicates(subset=['customer_unique_id'], keep='first', inplace=True)\n",
    "\n",
    "# Save lite df\n",
    "file = './data/olist_customers_dataset_lite.csv'\n",
    "with open(file, 'wb+') as f:\n",
    "    _ = df_customers_lite.to_csv(f, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement et nettoyage des données **orders**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99441 entries, 0 to 99440\n",
      "Data columns (total 8 columns):\n",
      " #   Column                         Non-Null Count  Dtype         \n",
      "---  ------                         --------------  -----         \n",
      " 0   order_id                       99441 non-null  object        \n",
      " 1   customer_id                    99441 non-null  object        \n",
      " 2   order_status                   99441 non-null  object        \n",
      " 3   order_purchase_timestamp       99441 non-null  datetime64[ns]\n",
      " 4   order_approved_at              99281 non-null  datetime64[ns]\n",
      " 5   order_delivered_carrier_date   97658 non-null  datetime64[ns]\n",
      " 6   order_delivered_customer_date  96476 non-null  datetime64[ns]\n",
      " 7   order_estimated_delivery_date  99441 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](5), object(3)\n",
      "memory usage: 6.1+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 99441 entries, 0 to 99440\n",
      "Data columns (total 8 columns):\n",
      " #   Column                         Non-Null Count  Dtype         \n",
      "---  ------                         --------------  -----         \n",
      " 0   order_id                       99441 non-null  object        \n",
      " 1   order_status                   99441 non-null  object        \n",
      " 2   order_purchase_timestamp       99441 non-null  datetime64[ns]\n",
      " 3   order_approved_at              99281 non-null  datetime64[ns]\n",
      " 4   order_delivered_carrier_date   97658 non-null  datetime64[ns]\n",
      " 5   order_delivered_customer_date  96476 non-null  datetime64[ns]\n",
      " 6   order_estimated_delivery_date  99441 non-null  datetime64[ns]\n",
      " 7   customer_unique_id             99441 non-null  object        \n",
      "dtypes: datetime64[ns](5), object(3)\n",
      "memory usage: 6.8+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# ORDERS\n",
    "\n",
    "df_orders = pd.read_csv(\"./data/olist_orders_dataset.csv\", sep=',', header=0, parse_dates=['order_purchase_timestamp', 'order_approved_at', 'order_delivered_carrier_date', 'order_delivered_customer_date', 'order_estimated_delivery_date'])\n",
    "df_orders.info()\n",
    "df_orders.drop_duplicates(inplace=True)\n",
    "\n",
    "# On normalize autant que possible le texte\n",
    "df_orders['order_status'] = df_orders['order_status'].apply(lambda x : unidecode(str(x).lower()))\n",
    "\n",
    "# On merge le \"customer_unique_id\" sur le \"customer_id\"\n",
    "df_orders = df_orders.merge(df_customers[['customer_id', 'customer_unique_id']], left_on='customer_id', right_on='customer_id')\n",
    "\n",
    "df_orders_lite = df_orders.drop(columns=['customer_id'], axis=1)\n",
    "\n",
    "print(df_orders_lite.info())\n",
    "\n",
    "# Save lite df\n",
    "file = './data/olist_orders_dataset_lite.csv'\n",
    "with open(file, 'wb+') as f:\n",
    "    _ = df_orders_lite.to_csv(f, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement et nettoyage des données **sellers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3095 entries, 0 to 3094\n",
      "Data columns (total 4 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   seller_id               3095 non-null   object\n",
      " 1   seller_zip_code_prefix  3095 non-null   int64 \n",
      " 2   seller_city             3095 non-null   object\n",
      " 3   seller_state            3095 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 96.8+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3095 entries, 0 to 3094\n",
      "Data columns (total 2 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   seller_id               3095 non-null   object\n",
      " 1   seller_zip_code_prefix  3095 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 72.5+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# SELLERS\n",
    "\n",
    "df_sellers = pd.read_csv(\"./data/olist_sellers_dataset.csv\", sep=',', header=0)\n",
    "df_sellers.info()\n",
    "df_sellers.drop_duplicates(inplace=True)\n",
    "\n",
    "# On normalize autant que possible le texte\n",
    "df_sellers['seller_city'] = df_sellers['seller_city'].apply(lambda x : unidecode(str(x).lower()))\n",
    "df_sellers['seller_state'] = df_sellers['seller_state'].apply(lambda x : unidecode(str(x).lower()))\n",
    "\n",
    "# On drop \"city\" et \"state\" car redondent\n",
    "df_sellers_lite = df_sellers.drop(columns=['seller_city', 'seller_state'], axis=1)\n",
    "\n",
    "print(df_sellers_lite.info())\n",
    "\n",
    "# Save lite df\n",
    "file = './data/olist_sellers_dataset_lite.csv'\n",
    "with open(file, 'wb+') as f:\n",
    "    _ = df_sellers_lite.to_csv(f, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement et nettoyage des données **reviews**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99224 entries, 0 to 99223\n",
      "Data columns (total 7 columns):\n",
      " #   Column                   Non-Null Count  Dtype         \n",
      "---  ------                   --------------  -----         \n",
      " 0   review_id                99224 non-null  object        \n",
      " 1   order_id                 99224 non-null  object        \n",
      " 2   review_score             99224 non-null  int64         \n",
      " 3   review_comment_title     11568 non-null  object        \n",
      " 4   review_comment_message   40977 non-null  object        \n",
      " 5   review_creation_date     99224 non-null  datetime64[ns]\n",
      " 6   review_answer_timestamp  99224 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](2), int64(1), object(4)\n",
      "memory usage: 5.3+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 99224 entries, 0 to 99223\n",
      "Data columns (total 7 columns):\n",
      " #   Column                   Non-Null Count  Dtype         \n",
      "---  ------                   --------------  -----         \n",
      " 0   review_id                99224 non-null  object        \n",
      " 1   order_id                 99224 non-null  object        \n",
      " 2   review_score             99224 non-null  int64         \n",
      " 3   review_comment_title     99224 non-null  object        \n",
      " 4   review_comment_message   99224 non-null  object        \n",
      " 5   review_creation_date     99224 non-null  datetime64[ns]\n",
      " 6   review_answer_timestamp  99224 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](2), int64(1), object(4)\n",
      "memory usage: 6.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# ORDER REVIEWS\n",
    "\n",
    "df_reviews = pd.read_csv(\"./data/olist_order_reviews_dataset.csv\", sep=',', header=0, parse_dates=['review_creation_date', 'review_answer_timestamp'])\n",
    "df_reviews.info()\n",
    "df_reviews.drop_duplicates(inplace=True)\n",
    "\n",
    "# On normalize autant que possible le texte\n",
    "df_reviews_update = df_reviews.copy()\n",
    "df_reviews_update['review_comment_title'] = df_reviews['review_comment_title'].apply(lambda x : unidecode(str(x).lower()))\n",
    "df_reviews_update['review_comment_message'] = df_reviews['review_comment_message'].apply(lambda x : unidecode(str(x).lower()))\n",
    "\n",
    "df_reviews_update.info()\n",
    "\n",
    "# Save lite df\n",
    "file = './data/olist_order_reviews_dataset_update.csv'\n",
    "with open(file, 'wb+') as f:\n",
    "    _ = df_reviews_update.to_csv(f, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement et nettoyage des données **items**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 112650 entries, 0 to 112649\n",
      "Data columns (total 7 columns):\n",
      " #   Column               Non-Null Count   Dtype         \n",
      "---  ------               --------------   -----         \n",
      " 0   order_id             112650 non-null  object        \n",
      " 1   order_item_id        112650 non-null  int64         \n",
      " 2   product_id           112650 non-null  object        \n",
      " 3   seller_id            112650 non-null  object        \n",
      " 4   shipping_limit_date  112650 non-null  datetime64[ns]\n",
      " 5   price                112650 non-null  float64       \n",
      " 6   freight_value        112650 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(2), int64(1), object(3)\n",
      "memory usage: 6.0+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 112650 entries, 0 to 112649\n",
      "Data columns (total 7 columns):\n",
      " #   Column               Non-Null Count   Dtype         \n",
      "---  ------               --------------   -----         \n",
      " 0   order_id             112650 non-null  object        \n",
      " 1   order_item_id        112650 non-null  int64         \n",
      " 2   product_id           112650 non-null  object        \n",
      " 3   seller_id            112650 non-null  object        \n",
      " 4   shipping_limit_date  112650 non-null  datetime64[ns]\n",
      " 5   price                112650 non-null  float64       \n",
      " 6   freight_value        112650 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(2), int64(1), object(3)\n",
      "memory usage: 6.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# ORDER ITEMS\n",
    "\n",
    "df_items = pd.read_csv(\"./data/olist_order_items_dataset.csv\", sep=',', header=0, parse_dates=['shipping_limit_date'])\n",
    "df_items.info()\n",
    "df_items.drop_duplicates(inplace=True)\n",
    "\n",
    "df_items.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement et nettoyage des données **payments**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 103886 entries, 0 to 103885\n",
      "Data columns (total 5 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   order_id              103886 non-null  object \n",
      " 1   payment_sequential    103886 non-null  int64  \n",
      " 2   payment_type          103886 non-null  object \n",
      " 3   payment_installments  103886 non-null  int64  \n",
      " 4   payment_value         103886 non-null  float64\n",
      "dtypes: float64(1), int64(2), object(2)\n",
      "memory usage: 4.0+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 103886 entries, 0 to 103885\n",
      "Data columns (total 5 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   order_id              103886 non-null  object \n",
      " 1   payment_sequential    103886 non-null  int64  \n",
      " 2   payment_type          103886 non-null  object \n",
      " 3   payment_installments  103886 non-null  int64  \n",
      " 4   payment_value         103886 non-null  float64\n",
      "dtypes: float64(1), int64(2), object(2)\n",
      "memory usage: 4.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# ORDER PAYMENTS\n",
    "\n",
    "df_payments = pd.read_csv(\"./data/olist_order_payments_dataset.csv\", sep=',', header=0)\n",
    "df_payments.info()\n",
    "df_payments.drop_duplicates(inplace=True)\n",
    "\n",
    "df_payments.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement et nettoyage des données **products**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32951 entries, 0 to 32950\n",
      "Data columns (total 9 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   product_id                  32951 non-null  object \n",
      " 1   product_category_name       32341 non-null  object \n",
      " 2   product_name_lenght         32341 non-null  float64\n",
      " 3   product_description_lenght  32341 non-null  float64\n",
      " 4   product_photos_qty          32341 non-null  float64\n",
      " 5   product_weight_g            32949 non-null  float64\n",
      " 6   product_length_cm           32949 non-null  float64\n",
      " 7   product_height_cm           32949 non-null  float64\n",
      " 8   product_width_cm            32949 non-null  float64\n",
      "dtypes: float64(7), object(2)\n",
      "memory usage: 2.3+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 32951 entries, 0 to 32950\n",
      "Data columns (total 9 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   product_id                  32951 non-null  object \n",
      " 1   product_category_name       32341 non-null  object \n",
      " 2   product_name_lenght         32341 non-null  float64\n",
      " 3   product_description_lenght  32341 non-null  float64\n",
      " 4   product_photos_qty          32341 non-null  float64\n",
      " 5   product_weight_g            32949 non-null  float64\n",
      " 6   product_length_cm           32949 non-null  float64\n",
      " 7   product_height_cm           32949 non-null  float64\n",
      " 8   product_width_cm            32949 non-null  float64\n",
      "dtypes: float64(7), object(2)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# ORDER PRODUCTS\n",
    "\n",
    "df_products = pd.read_csv(\"./data/olist_products_dataset.csv\", sep=',', header=0)\n",
    "df_products.info()\n",
    "df_products.drop_duplicates(inplace=True)\n",
    "\n",
    "df_products.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation des tables sqlite avec les modèles sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loguru import logger\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import scoped_session, sessionmaker\n",
    "from unidecode import unidecode\n",
    "\n",
    "import model\n",
    "\n",
    "DATABASE_URL = 'sqlite:///./db/olist.db'\n",
    "\n",
    "def init_db(uri):\n",
    "    engine = create_engine(uri)\n",
    "    db_session = scoped_session(sessionmaker(autocommit=False, autoflush=False, bind=engine))\n",
    "    model.Base.query = db_session.query_property()\n",
    "    model.Base.metadata.drop_all(bind=engine)\n",
    "    model.Base.metadata.create_all(bind=engine)\n",
    "    return db_session\n",
    "\n",
    "def insert_record(csv, model_class, session, parse_dates=False):\n",
    "    try:\n",
    "        data = pd.read_csv(csv, sep=',', header=0, parse_dates=parse_dates)\n",
    "        for row_dict in data.replace({np.nan: None}).to_dict(orient=\"records\"):\n",
    "            record = model_class(**row_dict)\n",
    "            session.add(record)\n",
    "        session.commit()\n",
    "    except Exception as error:\n",
    "        logger.exception(error)\n",
    "        session.rollback()\n",
    "        return\n",
    "    logger.info(f\"[{model_class.__name__}] OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-24 15:28:11.592 | INFO     | __main__:insert_record:29 - [Geolocation] OK\n",
      "2022-03-24 15:28:18.074 | INFO     | __main__:insert_record:29 - [Customers] OK\n",
      "2022-03-24 15:28:18.247 | INFO     | __main__:insert_record:29 - [Sellers] OK\n",
      "2022-03-24 15:28:30.027 | INFO     | __main__:insert_record:29 - [Orders] OK\n",
      "2022-03-24 15:28:39.847 | INFO     | __main__:insert_record:29 - [OrderReviews] OK\n",
      "2022-03-24 15:28:48.986 | INFO     | __main__:insert_record:29 - [OrderItems] OK\n",
      "2022-03-24 15:28:55.951 | INFO     | __main__:insert_record:29 - [OrderPayments] OK\n",
      "2022-03-24 15:28:58.480 | INFO     | __main__:insert_record:29 - [Products] OK\n"
     ]
    }
   ],
   "source": [
    "# inserssion dans une base de donnée relationnel\n",
    "session = init_db(DATABASE_URL)\n",
    "insert_record(\"./data/olist_geolocation_dataset_lite.csv\", model.Geolocation, session)\n",
    "insert_record(\"./data/olist_customers_dataset_lite.csv\", model.Customers, session)\n",
    "insert_record(\"./data/olist_sellers_dataset_lite.csv\", model.Sellers, session)\n",
    "insert_record(\"./data/olist_orders_dataset_lite.csv\", model.Orders, session,\n",
    "              parse_dates=['order_purchase_timestamp', 'order_approved_at', 'order_delivered_carrier_date', 'order_delivered_customer_date', 'order_estimated_delivery_date'])\n",
    "insert_record(\"./data/olist_order_reviews_dataset_update.csv\", model.OrderReviews, session, parse_dates=['review_creation_date', 'review_answer_timestamp'])\n",
    "insert_record(\"./data/olist_order_items_dataset.csv\", model.OrderItems, session, parse_dates=['shipping_limit_date'])\n",
    "insert_record(\"./data/olist_order_payments_dataset.csv\", model.OrderPayments, session)\n",
    "insert_record(\"./data/olist_products_dataset.csv\", model.Products, session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export du notebook en HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook P5_01_notebooknettoyage.ipynb to html\n",
      "[NbConvertApp] Writing 614238 bytes to P5_01_notebooknettoyage.html\n",
      "[NbConvertApp] Converting notebook P5_02_notebookanalyse.ipynb to html\n",
      "[NbConvertApp] Writing 19632329 bytes to P5_02_notebookanalyse.html\n",
      "[NbConvertApp] Converting notebook P5_03_notebookproduction.ipynb to html\n",
      "[NbConvertApp] Writing 910310 bytes to P5_03_notebookproduction.html\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --config nbconvert/config_html.py"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1146c6ec23184d6ddc9ddf58267b2d813dfa7d3b60507d0265311244441db098"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('jupyter')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
